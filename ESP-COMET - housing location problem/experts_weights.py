import numpy as np

experts_weights = np.array([
    [ # EXPERT 1
        [0.12, 0.10, 0.12, 0.05, 0.15, 0.20, 0.01, 0.06, 0.08, 0.11], # Fixed Point Scoring (FPS)
        [0.14, 0.12, 0.05, 0.03, 0.16, 0.18, 0.01, 0.10, 0.09, 0.07], # Ranking Method (RM)
        [0.13, 0.14, 0.04, 0.03, 0.17, 0.19, 0.02, 0.09, 0.08, 0.06], # Simple Attribute Rating Technique (SMART)
        [0.13, 0.14, 0.04, 0.03, 0.18, 0.19, 0.01, 0.09, 0.08, 0.06], # Ratio Weighting Method (RWM)
        [0.10, 0.09, 0.03, 0.02, 0.21, 0.34, 0.01, 0.07, 0.05, 0.05]  # Analytical Hierarchy Process (AHP)
    ],
    [ # EXPERT 2
        [0.20, 0.12, 0.10, 0.01, 0.15, 0.10, 0.01, 0.05, 0.25, 0.01],
        [0.16, 0.09, 0.05, 0.03, 0.14, 0.12, 0.01, 0.10, 0.18, 0.07],
        [0.15, 0.10, 0.09, 0.07, 0.14, 0.10, 0.03, 0.04, 0.17, 0.06],
        [0.16, 0.07, 0.03, 0.05, 0.14, 0.12, 0.01, 0.09, 0.18, 0.10],
        [0.09, 0.06, 0.02, 0.02, 0.12, 0.09, 0.01, 0.15, 0.30, 0.10]
    ],
    [ # EXPERT 3
        [0.30, 0.01, 0.11, 0.01, 0.01, 0.11, 0.23, 0.20, 0.01, 0.01],
        [0.18, 0.03, 0.14, 0.16, 0.09, 0.10, 0.12, 0.07, 0.05, 0.01],
        [0.12, 0.10, 0.09, 0.09, 0.08, 0.07, 0.11, 0.11, 0.12, 0.06],
        [0.18, 0.10, 0.09, 0.12, 0.03, 0.07, 0.14, 0.16, 0.05, 0.01],
        [0.23, 0.15, 0.14, 0.08, 0.10, 0.08, 0.06, 0.03, 0.04, 0.03]
    ],
    [ # EXPERT 4
        [0.15, 0.05, 0.05, 0.05, 0.15, 0.06, 0.15, 0.10, 0.12, 0.12],
        [0.16, 0.05, 0.03, 0.01, 0.18, 0.07, 0.12, 0.09, 0.10, 0.14],
        [0.16, 0.06, 0.06, 0.05, 0.12, 0.07, 0.11, 0.08, 0.09, 0.15],
        [0.19, 0.04, 0.03, 0.01, 0.11, 0.06, 0.16, 0.08, 0.09, 0.18],
        [0.28, 0.02, 0.02, 0.03, 0.15, 0.04, 0.10, 0.10, 0.12, 0.09]
    ],
    [ # EXPERT 5
        [0.15, 0.03, 0.03, 0.03, 0.15, 0.15, 0.06, 0.10, 0.10, 0.2],
        [0.14, 0.05, 0.03, 0.01, 0.18, 0.07, 0.09, 0.12, 0.10, 0.16],
        [0.11, 0.08, 0.07, 0.06, 0.13, 0.09, 0.10, 0.11, 0.08, 0.12],
        [0.14, 0.05, 0.03, 0.01, 0.18, 0.12, 0.10, 0.09, 0.07, 0.16],
        [0.13, 0.05, 0.02, 0.01, 0.20, 0.06, 0.09, 0.05, 0.08, 0.26]
    ],
    [ # EXPERT 6
        [0.01, 0.10, 0.3, 0.30, 0.02, 0.05, 0.10, 0.10, 0.01, 0.01],
        [0.07, 0.10, 0.18, 0.16, 0.09, 0.12, 0.14, 0.05, 0.03, 0.01],
        [0.06, 0.13, 0.23, 0.18, 0.05, 0.07, 0.09, 0.05, 0.05, 0.04],
        [0.05, 0.14, 0.22, 0.17, 0.04, 0.07, 0.13, 0.08, 0.01, 0.02],
        [0.02, 0.15, 0.25, 0.26, 0.03, 0.03, 0.11, 0.06, 0.03, 0.01]
    ],
    [ # EXPERT 7
        [0.15, 0.05, 0.03, 0.01, 0.05, 0.25, 0.01, 0.30, 0.05, 0.10],
        [0.14, 0.07, 0.03, 0.05, 0.09, 0.16, 0.01, 0.18, 0.10, 0.12],
        [0.12, 0.06, 0.06, 0.07, 0.11, 0.13, 0.05, 0.14, 0.10, 0.11],
        [0.14, 0.05, 0.07, 0.03, 0.10, 0.16, 0.01, 0.18, 0.09, 0.12],
        [0.14, 0.01, 0.02, 0.02, 0.15, 0.11, 0.01, 0.32, 0.07, 0.11]
    ],
    [ # EXPERT 8
        [0.05, 0.10, 0.05, 0.05, 0.10, 0.05, 0.10, 0.30, 0.10, 0.10],
        [0.01, 0.12, 0.05, 0.03, 0.07, 0.16, 0.10, 0.18, 0.14, 0.09],
        [0.02, 0.06, 0.04, 0.03, 0.08, 0.15, 0.11, 0.22, 0.17, 0.07],
        [0.01, 0.07, 0.04, 0.02, 0.08, 0.15, 0.12, 0.2, 0.17, 0.10],
        [0.01, 0.03, 0.02, 0.02, 0.06, 0.14, 0.08, 0.28, 0.21, 0.10]
    ],
    [ # EXPERT 9
        [0.10, 0.05, 0.05, 0.05, 0.10, 0.20, 0.05, 0.10, 0.20, 0.10],
        [0.10, 0.05, 0.03, 0.01, 0.14, 0.16, 0.07, 0.12, 0.18, 0.09],
        [0.11, 0.06, 0.05, 0.05, 0.10, 0.15, 0.06, 0.12, 0.16, 0.09],
        [0.10, 0.07, 0.03, 0.01, 0.16, 0.14, 0.05, 0.12, 0.18, 0.09],
        [0.07, 0.03, 0.02, 0.02, 0.12, 0.17, 0.01, 0.10, 0.33, 0.06]
    ],
    [ # EXPERT 10
        [0.15, 0.08, 0.06, 0.06, 0.15, 0.15, 0.08, 0.15, 0.02, 0.10],
        [0.18, 0.09, 0.03, 0.01, 0.10, 0.16, 0.05, 0.14, 0.07, 0.12],
        [0.25, 0.05, 0.02, 0.02, 0.12, 0.15, 0.03, 0.20, 0.05, 0.07],
        [0.22, 0.07, 0.02, 0.01, 0.12, 0.14, 0.03, 0.18, 0.06, 0.10],
        [0.27, 0.03, 0.01, 0.01, 0.15, 0.12, 0.03, 0.21, 0.03, 0.10]
    ]
])